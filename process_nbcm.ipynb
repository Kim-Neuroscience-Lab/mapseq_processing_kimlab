{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e06f9-5769-45a5-8e28-f2b8a3e7e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Content from master.py\n",
    "### Imports\n",
    "import os\n",
    "import sympy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from sympy import symbols, Product, Array, N\n",
    "from sympy.printing import latex\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import patches\n",
    "import seaborn as sn\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import friedmanchisquare, kruskal, binomtest\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.preprocessing import normalize \n",
    "import itertools\n",
    "from adjustText import adjust_text\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import upsetplot as up\n",
    "\n",
    "### User Configuration\n",
    "\n",
    "# Directories and Save Name\n",
    "out_dir = \"/home/mwjacobs/test_stats/output/\"\n",
    "save_name = \"P3_combined\"\n",
    "\n",
    "### Data Inputs\n",
    "##This is your nbcm (individuals are provided by CSHL python code output. A combined file could be made by hand.\"\n",
    "data_file = r'/home/mwjacobs/mapseq_data_preprocess/p3_nbcm_combined_for-preprocess - Sheet1.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#This switch is for excluding some columns\n",
    "full_data = True\n",
    "\n",
    "\n",
    "motif_join = '+'\n",
    "\n",
    "\n",
    "\n",
    "### Helper Functions\n",
    "\n",
    "def calculate_projections_from_matrix(matrix):\n",
    "    \"\"\"Calculate projections as the count of non-zero values in each column.\"\"\"\n",
    "    column_counts = {region: np.count_nonzero(matrix[:, idx]) for idx, region in enumerate([\n",
    "        'RSP', 'PM', 'AM', 'A', 'RL', 'AL', 'LM', 'Cerebellum'])}\n",
    "    # Remove the last column (Cerebellum) if not needed\n",
    "    column_counts.pop('Cerebellum', None)\n",
    "    return column_counts\n",
    "\n",
    "def calculate_total_projections(projections):\n",
    "    return sum(projections.values())\n",
    "\n",
    "def solve_for_roots(projections, observed_cells):\n",
    "    N0, k = symbols('N_0 k')\n",
    "    m = len(projections) - 1\n",
    "    s = Array(list(projections.values()))\n",
    "    pi = (1 - Product((1 - (s[k]/N0)), (k, 0, m)).doit())\n",
    "    soln = sympy.solve(pi * N0 - observed_cells)\n",
    "    roots = [N(x).as_real_imag()[0] for x in soln]\n",
    "    return roots, pi\n",
    "\n",
    "def save_latex_expression(expression, title, filename):\n",
    "    latex_output = latex(expression)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.text(0.5, 0.5, f\"${latex_output}$\", fontsize=14, va='center', ha='center', wrap=True)\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def calculate_probabilities(projections, total_projections):\n",
    "    return {region: (count / total_projections) for region, count in projections.items()}\n",
    "\n",
    "def binomial_test(value, total, probability):\n",
    "    return binomtest(value, n=total, p=probability).pvalue\n",
    "\n",
    "def normalize_rows(matrix):\n",
    "    \"\"\"Normalize rows of a matrix by their maximum value.\"\"\"\n",
    "    return np.apply_along_axis(lambda x: x / np.amax(x) if np.amax(x) > 0 else x, axis=1, arr=matrix)\n",
    "\n",
    "def clean_and_filter(matrix):\n",
    "    \"\"\"Perform cleaning and filtering on the matrix.\"\"\"\n",
    "    # Remove rows with all zero values\n",
    "    matrix = matrix[np.any(matrix, axis=1)]\n",
    "    \n",
    "    # Remove rows with all zero target values (columns 0-6)\n",
    "    matrix = matrix[np.any(matrix[:, :-1], axis=1)]\n",
    "\n",
    "    # Remove rows where column 7 (DLS) has positive values\n",
    "    matrix = matrix[matrix[:, 7] <= 0]\n",
    "\n",
    "    # Apply a threshold filter for minimum counts in target columns (columns 0-6)\n",
    "    min_threshold = 2\n",
    "    matrix = matrix[np.amax(matrix[:, :-1], axis=1) >= min_threshold]\n",
    "\n",
    "    return matrix\n",
    "\n",
    "### Main Calculations\n",
    "\n",
    "# Load barcodes\n",
    "barcodematrix = np.genfromtxt(data_file, delimiter=',')\n",
    "barcodematrix = np.array(barcodematrix, dtype=np.float64)\n",
    "print(\"Barcode Matrix Shape:\", barcodematrix.shape)\n",
    "\n",
    "# Perform cleaning and filtering\n",
    "filtered_matrix = clean_and_filter(barcodematrix)\n",
    "print(\"Filtered Matrix Shape:\", filtered_matrix.shape)\n",
    "\n",
    "# Normalize rows of the filtered matrix\n",
    "normalized_matrix = normalize_rows(filtered_matrix)\n",
    "print(\"Normalized Matrix Shape:\", normalized_matrix.shape)\n",
    "\n",
    "# Drop the last column (Cerebellum)\n",
    "normalized_matrix = np.delete(normalized_matrix, 7, axis=1)\n",
    "\n",
    "# Save normalized matrix to CSV with headers\n",
    "columns = [\"RSP\", \"PM\", \"AM\", \"A\", \"RL\", \"AL\", \"LM\"]\n",
    "normalized_matrix_file = os.path.join(out_dir, f\"{save_name}_Normalized_Matrix.csv\")\n",
    "pd.DataFrame(normalized_matrix, columns=columns).to_csv(normalized_matrix_file, index=False, float_format=\"%.8f\")\n",
    "print(f\"Normalized matrix saved to: {normalized_matrix_file}\")\n",
    "\n",
    "# Calculate observed cells dynamically\n",
    "observed_cells = filtered_matrix.shape[0]  # Number of rows after filtering\n",
    "print(f\"Observed Cells: {observed_cells}\")\n",
    "\n",
    "# Calculate projections dynamically from the filtered matrix\n",
    "projections = calculate_projections_from_matrix(filtered_matrix)\n",
    "print(\"Projections:\", projections)\n",
    "\n",
    "# Calculate total projections\n",
    "total_projections = calculate_total_projections(projections)\n",
    "print(f\"Total Projections: {total_projections}\")\n",
    "\n",
    "# Solve for roots and simplify Pi\n",
    "roots, pi = solve_for_roots(projections, observed_cells)\n",
    "print(\"Roots:\", roots)\n",
    "\n",
    "simplified_pi = sympy.simplify(pi)\n",
    "print(\"Simplified Pi:\", simplified_pi)\n",
    "\n",
    "# Save LaTeX representation of simplified Pi\n",
    "save_latex_expression(simplified_pi, \"Simplified Pi Visualization\", os.path.join(out_dir, f\"{save_name}_Simplified_Pi.png\"))\n",
    "\n",
    "# Calculate probabilities\n",
    "psdict = calculate_probabilities(projections, total_projections)\n",
    "print(\"Region-specific Probabilities:\", psdict)\n",
    "\n",
    "# Solve for p_e\n",
    "pe = symbols('p_e')\n",
    "#pe = pe_num\n",
    "solution = sympy.solve((1 - (1 - pe)**len(projections)) * total_projections - observed_cells, [pe], force=True)\n",
    "if solution:\n",
    "    pe_num = float(solution[0])\n",
    "    print(\"Derived p_e:\", pe_num)\n",
    "else:\n",
    "    raise ValueError(\"No valid solution for p_e found.\")\n",
    "\n",
    "# Numerical Calculations\n",
    "scaled_value = psdict['RSP'] * psdict['PM']\n",
    "calculated_value = (1 - (1 - pe_num)**len(projections)) * total_projections\n",
    "print(\"Calculated Value:\", calculated_value)\n",
    "\n",
    "# Save LaTeX representation of calculated value\n",
    "save_latex_expression(calculated_value, \"Calculated Value Visualization\", os.path.join(out_dir, f\"{save_name}_Calculated_Value.png\"))\n",
    "\n",
    "# Perform statistical tests\n",
    "std_dev = np.sqrt(scaled_value * total_projections * (1 - scaled_value))\n",
    "print(\"Standard Deviation:\", std_dev)\n",
    "\n",
    "binomial_p_value = binomial_test(94, total_projections, scaled_value)\n",
    "print(\"Binomial Test Result (P-Value):\", binomial_p_value)\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    \"Roots\": roots,\n",
    "    \"Simplified Pi\": [simplified_pi],\n",
    "    \"Region-specific Probabilities\": list(psdict.values()),\n",
    "    \"Calculated Value\": [calculated_value],\n",
    "    \"Standard Deviation\": [std_dev],\n",
    "    \"Binomial Test Result (P-Value)\": [binomial_p_value]\n",
    "}\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "for key, value in results.items():\n",
    "    pd.DataFrame({key: value}).to_csv(os.path.join(out_dir, f\"{save_name}_{key.replace(' ', '_')}.csv\"), index=False)\n",
    "\n",
    "### Visualizations\n",
    "# Region-specific probabilities\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(psdict.keys(), psdict.values())\n",
    "plt.title(\"Region-specific Probabilities\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, f\"{save_name}_Region_Probabilities.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Roots scatterplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(range(len(roots)), roots)\n",
    "plt.title(\"Roots\")\n",
    "plt.ylabel(\"Root Value\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, f\"{save_name}_Roots.png\"))\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68dca59-a443-4245-85bb-4c1f45f34bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content from master_2.py\n",
    "### Analysis and Plotting Integration\n",
    "\n",
    "#Where is the normalized_matrix.csv\n",
    "data_dir = out_dir\n",
    "file_name = os.path.join(f\"{save_name}_Normalized_Matrix.csv\")\n",
    "\n",
    "\n",
    "# Load normalized matrix as input for analysis\n",
    "normalized_matrix_file = os.path.join(out_dir, f\"{save_name}_Normalized_Matrix.csv\")\n",
    "normalized_matrix = pd.read_csv(normalized_matrix_file)\n",
    "\n",
    "# Ensure 'analysis' subdirectory exists within 'out_dir'\n",
    "analysis_dir = os.path.join(out_dir, 'analysis')\n",
    "os.makedirs(analysis_dir, exist_ok=True)\n",
    "\n",
    "#Where do you want the analysis output to go?\n",
    "plot_dir = analysis_dir\n",
    "\n",
    "n0 = observed_cells #import from stats at beginning\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "def load_df(file, remove_cols=['RSP'], subset=['PM','AM','A','RL','AL','LM']):\n",
    "    \"\"\"\n",
    "    Loads excel file specified in file which is a string for the full path\n",
    "    Excel should have column names as the first row (header)\n",
    "    remove_col specifies the names of columns to remove (list, e.g. [\"DLS\"])\n",
    "    subset specifies the names of columns to keep (drop others, e.g. 'LH', 'BLA', 'PFC', 'NAc'])\n",
    "    \"\"\"\n",
    "    experiment_ = pd.read_csv(file,header=0) #pd.read_excel(file,header=0)\n",
    "    print(experiment_.columns)\n",
    "    df = experiment_\n",
    "    #df.columns = colnames\n",
    "    if remove_cols is not None:\n",
    "        try:\n",
    "            df = df.drop(columns=remove_cols)\n",
    "        except Exception as e:\n",
    "            print(\"!!! Error: Could not remove columns. Column not found in remove_cols\")\n",
    "    if subset is not None:\n",
    "        try:\n",
    "            df = df[subset] #limit, removes BNST and CeA\n",
    "        except Exception as e:\n",
    "            print(\"!!! Error: Could not subset columns. Column not found in subset\")\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "Change the file path:\n",
    "\"\"\"\n",
    "file_path = data_dir + file_name\n",
    "if full_data:\n",
    "    #Load full data set\n",
    "    df = load_df(file_path, remove_cols=None,subset=None)\n",
    "else:\n",
    "    #Load special regions:\n",
    "    df = load_df(file_path, remove_cols=['RSP'], subset=['PM','AM','A','RL','AL','LM'])\n",
    "\n",
    "print(\"df shape: {}\".format(df.shape))\n",
    "print(\"DF Head:\")\n",
    "print(df.head())\n",
    "print(\"Number of NAs:\")\n",
    "print(df.isnull().sum())\n",
    "##PFC NAc LS DLS BNST LH BLA CeA  | CM11 - CM18\n",
    "\n",
    "# Find optimal number of clusters\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    km = k_means(df.to_numpy(), n_clusters=k)\n",
    "    #km = km.fit(data_transformed)\n",
    "    Sum_of_squared_distances.append(km[2])\n",
    "len(Sum_of_squared_distances)\n",
    "\n",
    "elbow_plt = plt.figure(figsize=(10,7))\n",
    "s1 = np.array(Sum_of_squared_distances[0:-1])\n",
    "s2 = np.array(Sum_of_squared_distances[1:])\n",
    "plt.plot(K[0:-1], np.abs(s2-s1), 'x-', color='red',label='Delta Inertia')\n",
    "plt.plot(K, Sum_of_squared_distances, 'x-', color='blue',label='Inertia')\n",
    "plt.xlabel('k',fontsize=20)\n",
    "plt.ylabel('Inertia',fontsize=20)\n",
    "plt.title('Elbow Method For Optimal k',fontsize=20)\n",
    "plt.legend()\n",
    "#Looks like optimal cluster number is 6\n",
    "\n",
    "elbow_plt.savefig(os.path.join(plot_dir, save_name + \"elbow_plot.pdf\"))\n",
    "\n",
    "km = k_means(df.to_numpy(), n_clusters=6) #THIS WAS INITIALLY 6, I THINK THEY PULL IT FROM BOX 1065 OUTPUT average below.\n",
    "km[0].shape\n",
    "\n",
    "df.to_csv(os.path.join(plot_dir, save_name + \"_motif_obs_exp.csv\"))\n",
    "\n",
    "scolors = ['black','red','orange','yellow'] #['lightblue','darkblue'] \n",
    "scm = LinearSegmentedColormap.from_list(\n",
    "        'white_to_red', scolors, N=100)\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1)\n",
    "fig.set_size_inches(10,10)\n",
    "clusters,regions = km[0].shape\n",
    "ax.set_title(\"K-means Clustering\")\n",
    "ax.set_xlabel(\"Regions\")\n",
    "ax.set_ylabel(\"Cluster\")\n",
    "ax.set_xticks(range(regions))\n",
    "ax.set_xticklabels(df.columns.to_list())\n",
    "##\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "##\n",
    "#g = np.linspace(0, 10, 1000)\n",
    "#I = np.sin(g) * np.cos(g[:, np.newaxis])\n",
    "#t = ax.imshow(I,cmap=scm,visible=False)\n",
    "#fig.colorbar(mappable=t)\n",
    "##\n",
    "ax.set_yticks(range(0,clusters,1))\n",
    "ax.set_yticklabels(range(1,clusters+1,1))\n",
    "X = range(regions)\n",
    "for i in range(km[0].shape[0]):\n",
    "    y = np.array([i]).repeat(regions)\n",
    "    #km[0][i]\n",
    "    size = km[0][i]\n",
    "    size = (size - size.min()) / (size.max() - size.min())\n",
    "    ax_ = ax.scatter(x=X,y=y,s=1000,cmap=scm,c=size)\n",
    "\n",
    "    #sn.regplot(x=X,y=y,ax=ax,scatter=False)\n",
    "    #sn.scatterplot(x=X,y=y,ax=ax,size=size,legend=None,sizes=(100, 500),hue=size,palette=scm)\n",
    "fig.colorbar(ax_,label='Projection Strength')\n",
    "\n",
    "fig.savefig(os.path.join(plot_dir, save_name + \"_kmeans.pdf\"))\n",
    "\n",
    "def concatenate_list_data(slist,join=motif_join):\n",
    "    result = []\n",
    "    for i in slist:\n",
    "        sub = ''\n",
    "        for j in i:\n",
    "            if sub:\n",
    "                sub = sub + join + str(j)\n",
    "            else:\n",
    "                sub += str(j)\n",
    "        result.append(sub)\n",
    "    return result\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def gen_motifs(r,labels): #r is number of regions, so number of motifis is 2^r\n",
    "    num_motifs = 2**r\n",
    "    motifs = np.zeros((num_motifs,r)).astype(bool)\n",
    "    motif_ids = list(powerset(np.arange(r)))\n",
    "    motif_labels = [] #list of labels e.g. PFC-LH or PFC-LS-BNST\n",
    "    for i in range(num_motifs):\n",
    "        idx = motif_ids[i]\n",
    "        motifs[i,idx] = True\n",
    "        #motif_labels.append(labels[[idx]].to_list())\n",
    "        label = labels[np.array(idx)].to_list() if idx else ['']\n",
    "        motif_labels.append(label)\n",
    "    return motifs, motif_labels\n",
    "\n",
    "def count_motifs(df,motifs,return_ids=False):\n",
    "    \"\"\"\n",
    "    Returns a vector with counts that indicated number of motifs present for each possible motif\n",
    "    A motif is a combination of target areas represented as a binary array, \n",
    "    e.g. [1,1,0] represents a motif where a cell targets the first two regions but not the 3rd\n",
    "    A motif can be obtained by simply thresholding each cell's projection strength vector such that\n",
    "    non-zero elements are 1.\n",
    "    Also returns the labels for each motif\n",
    "    \"\"\"\n",
    "    cells, regions = df.shape\n",
    "    data = df.to_numpy().astype(bool)\n",
    "    #np.unique(df.to_numpy().astype(bool),axis=0,return_counts=True)\n",
    "    #if motifs is None: motifs = gen_motifs(regions)\n",
    "    counts = np.zeros(motifs.shape[0])\n",
    "    cell_ids = []\n",
    "    for i in range(motifs.shape[0]): #loop through motifs (128x7)\n",
    "        cell_ids_ = []\n",
    "        for j in range(data.shape[0]): #loop through observed data cells X regions\n",
    "            if np.array_equal(motifs[i],data[j]):\n",
    "                counts[i] = counts[i] + 1\n",
    "                cell_ids_.append(j)\n",
    "        cell_ids.append(cell_ids_)\n",
    "        \n",
    "    if return_ids:\n",
    "        return counts, cell_ids#, motifs\n",
    "    else:\n",
    "        return counts\n",
    "\n",
    "#def count_motifs_optim(df,motifs):\n",
    "#    \"\"\"\n",
    "#    ** Optimized version\n",
    "#    Returns a vector with counts that indicated number of motifs present for each possible motif\n",
    "#    A motif is a combination of target areas represented as a binary array, \n",
    "#    e.g. [1,1,0] represents a motif where a cell targets the first two regions but not the 3rd\n",
    "#    A motif can be obtained by simply thresholding each cell's projection strength vector such that\n",
    "#    non-zero elements are 1.\n",
    "#    Also returns the labels for each motif\n",
    "#    *optim version doesn't return cell_ids\n",
    "#    \"\"\"\n",
    "#    cells, regions = df.shape\n",
    "#    data = df.to_numpy().astype(bool)\n",
    "#    #if motifs is None: motifs = gen_motifs(regions)\n",
    "#    counts = np.zeros(motifs.shape[0])\n",
    "#    for i in range(motifs.shape[0]): #loop through observed data cells X regions\n",
    "#        res = (motifs[i] == data).all(axis=1).nonzero() #tells which motif this cell is\n",
    "#       counts[i] = res[0].shape[0]\n",
    "#    return counts\n",
    "\n",
    "def zip_with_scalar(l, o):\n",
    "    return zip(l, itertools.repeat(o))\n",
    "\n",
    "motifs, motif_labels = gen_motifs(df.shape[1],df.columns)\n",
    "\n",
    "dcounts, cell_ids = count_motifs(df,motifs, return_ids=True) #observed data\n",
    "\n",
    "def convert_counts_to_df(columns,counts,labels):\n",
    "    \"\"\"\n",
    "    Deprecated. Use get_obs_exp(...) instead.\n",
    "    \n",
    "    Returns dataframe showing cell counts for each motif\n",
    "    \"\"\"\n",
    "    motifdf = pd.DataFrame(columns=columns)\n",
    "    for i in range(len(counts)):\n",
    "        #other = {motif_labels[i][j]:1 for j in range(len(motif_labels[i]))}\n",
    "        cols = labels[i]\n",
    "        if len(cols) == 1 and not cols[0]:\n",
    "            continue\n",
    "        motifdf.loc[i,cols] = 1\n",
    "        motifdf.loc[i,\"Count\"] = counts[i]\n",
    "    return motifdf.fillna(0).infer_objects(copy=False)\n",
    "\n",
    "motif_df = convert_counts_to_df(df.columns,dcounts,motif_labels)\n",
    "\n",
    "from sympy import N\n",
    "\n",
    "def get_expected_counts(motifs, num_regions = 7, prob_edge=pe_num,n=n0):\n",
    "    # Ensure variables are numeric\n",
    "    prob_edge = float(prob_edge.evalf()) if hasattr(prob_edge, \"evalf\") else float(prob_edge)\n",
    "    #motif_set = set(['PFC', 'NAc', 'LS', 'BNST', 'LH', 'BA', 'CeA'])\n",
    "    n_motifs = len(motifs)\n",
    "    res = np.zeros(n_motifs)\n",
    "    probs = np.zeros(n_motifs)\n",
    "    for i,motif in enumerate(motifs):\n",
    "        e1 = int(len(motif))\n",
    "        e2 = num_regions - e1\n",
    "        p = (prob_edge ** e1) * (1 - prob_edge) ** e2\n",
    "        exp = float(N(p)) * n\n",
    "        res[i] = exp\n",
    "        probs[i] = p\n",
    "    res[0] = 0\n",
    "    return res, probs\n",
    "\n",
    "exp_counts, motif_probs = get_expected_counts(motif_labels)\n",
    "df_obs_exp = pd.DataFrame(data=[concatenate_list_data(motif_labels),\\\n",
    "                                dcounts,\\\n",
    "                                exp_counts.astype(int)]).T\n",
    "df_obs_exp.columns = ['Motif','Observed','Expected']\n",
    "df_obs_exp.to_csv(os.path.join(plot_dir, save_name + \"_motif_obs_exp.csv\"))\n",
    "df_obs_exp\n",
    "\n",
    "##CHATGPT suggested addition to give a csv without the null combination from the powerset.\n",
    "\n",
    "exp_counts, motif_probs = get_expected_counts(motif_labels)\n",
    "df_obs_exp = pd.DataFrame(data=[concatenate_list_data(motif_labels), dcounts, exp_counts.astype(int)]).T\n",
    "df_obs_exp.columns = ['Motif', 'Observed', 'Expected']\n",
    "\n",
    "# Exclude empty motifs\n",
    "df_obs_exp = df_obs_exp[df_obs_exp['Motif'] != \"\"]  # Adjust condition as needed for your data format - chatGPT\n",
    "\n",
    "# Save filtered data to CSV\n",
    "df_obs_exp.to_csv(\n",
    "    os.path.join(plot_dir, save_name + \"_motif_obs_exp_filtered.csv\"), \n",
    "    index=False\n",
    ")\n",
    "\n",
    "\n",
    "def standardize_pos(x):\n",
    "    return (x + 1) / (x.std())\n",
    "def standardize(x):\n",
    "    return (x + 1e-13) / (x.max() - x.min())\n",
    "def subset_list(lis, ids):\n",
    "    return [lis[i] for i in ids]\n",
    "\n",
    "def get_motif_sig_pts(dcounts,labels,\\\n",
    "                            prob_edge=0.120287583118229, n0 = 8404, \\\n",
    "                      exclude_zeros=True, \\\n",
    "                      p_transform=lambda x: -1 * np.log10(x)):\n",
    "    #dcounts: motif counts from observed data\n",
    "    num_motifs = dcounts.shape[0]\n",
    "    expected, probs = get_expected_counts(labels, prob_edge=prob_edge,n=n0)\n",
    "    assert dcounts.shape[0] == expected.shape[0]\n",
    "    if exclude_zeros:\n",
    "        nonzid = np.nonzero(dcounts)[0]\n",
    "    else:\n",
    "        nonzid = np.arange(dcounts.shape[0])\n",
    "    num_nonzid_motifs = nonzid.shape[0]\n",
    "    dcounts_ = dcounts[nonzid]\n",
    "    expected_ = expected[nonzid]\n",
    "    probs_ = probs[nonzid]\n",
    "    #Effect size is log2(observed/expected)\n",
    "    effect_size = np.log2((dcounts_ + 1) / (expected_ + 1))\n",
    "    matches = np.zeros(num_nonzid_motifs)\n",
    "    assert dcounts_.shape[0] == expected_.shape[0]\n",
    "    dcounts_ = dcounts_.astype(int)\n",
    "    for i in range(num_nonzid_motifs):\n",
    "        #pi = probs_[i] if probs_[i] > 0 else 1.0e-99\n",
    "        #dcounts_[i] = int(dcounts_[i])  # Force integer conversion\n",
    "        pi = max(probs_[i], 1e-10) #avoid zero or very small probs\n",
    "        matches[i] = binomtest(int(dcounts_[i]),n=n0,p=pi).pvalue #alternative='greater'     ########IF I REMOVE THIS AND TRY\n",
    "        #matches[i] = matches[i] if matches[i] > 0 else 1.0e-10\n",
    "        matches[i] = max(matches[i], 1e-10)\n",
    "    matches = p_transform(matches)\n",
    "    #matches is the significance level\n",
    "    res = zip(effect_size, matches)\n",
    "    mlabels = [labels[h] for h in nonzid]\n",
    "    return list(res), mlabels\n",
    "\n",
    "sigs, slabels = get_motif_sig_pts(dcounts,motif_labels,exclude_zeros=True)\n",
    "\n",
    "#Bonferroni correction: p-threshold / Num comparisons\n",
    "pcutoff = -1*np.log10(0.05 / len(slabels)) # = 3.1 for thresh of 0.05 or 3.6 for thresh of 0.01 for n=63\n",
    "\n",
    "list_sig = [i for (i,(e,s)) in enumerate(sigs) if s > pcutoff ]\n",
    "color_labels = ['gray' for i in range(len(sigs))]\n",
    "for i in list_sig:\n",
    "    e,s = sigs[i]\n",
    "    if e > 0: #overrepresented\n",
    "        color_labels[i] = 'red'\n",
    "    else:\n",
    "        color_labels[i] = 'blue'\n",
    "#color_labels\n",
    "\n",
    "hide_singlets = True\n",
    "if hide_singlets:\n",
    "    mask = [i for (i,l) in enumerate(slabels) if len(l) > 1]\n",
    "#subset_list(slabels,[1,5,7])\n",
    "fig,ax = plt.subplots(1,1)#plt.figure(figsize=(13,11))\n",
    "fig.set_size_inches(20,20)\n",
    "#ax.set_ylim([0,12])\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "ax.set_title(save_name.replace('_',''),fontsize=16)\n",
    "ax.set_xlabel(\"Effect Size \\n$log_2($observed/expected$)$\",fontsize=16)\n",
    "ax.set_ylabel(\"Significance\\n $-log_{10}(P)$\",fontsize=16)\n",
    "ax.axhline(y=pcutoff, linestyle='--')\n",
    "ax.axvline(x=0, linestyle='--')\n",
    "ax.text(x=-.5,y=pcutoff+0.05,s='P-value cutoff',fontsize=16)\n",
    "##CHATGPT UPDATES FOR FORMATTING\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(*zip(*subset_list(sigs, mask)), c=subset_list(color_labels, mask))\n",
    "\n",
    "# Prepare text labels\n",
    "pretty_slabels = concatenate_list_data(subset_list(slabels, mask))\n",
    "coordinates = subset_list(sigs, mask)\n",
    "texts = []\n",
    "\n",
    "for n, (z, y) in enumerate(coordinates):\n",
    "    txt = pretty_slabels[n]\n",
    "    texts.append(ax.text(z, y, txt, fontsize=12))\n",
    "\n",
    "# Adjust y-axis limits\n",
    "y_vals = [y for _, y in subset_list(sigs, mask)]\n",
    "padding = 0.1 * (max(y_vals) - min(y_vals))  # Add 10% padding\n",
    "ax.set_ylim(min(y_vals) - padding, max(y_vals) + padding)\n",
    "\n",
    "# Adjust text positions to avoid overlap\n",
    "adjust_text(\n",
    "    texts,\n",
    "    #only_move={'points': 'y', 'text': 'y'},  # Allow vertical movement\n",
    "    arrowprops=dict(\n",
    "        arrowstyle=\"->\",\n",
    "        color='gray',\n",
    "        lw=1,\n",
    "        shrinkA=1,  # These values won't matter much for adjust_text\n",
    "        shrinkB=1\n",
    "    ),\n",
    "    expand_points=(1.5, 2.5),  # Add padding around points\n",
    "    force_text=1,  # Increase separation force for text\n",
    "    force_points=1  # Increase separation force for points\n",
    ")\n",
    "\n",
    "##ORIGINAL CODE\n",
    "#ax.scatter(*zip(*subset_list(sigs,mask)),c=subset_list(color_labels,mask))\n",
    "#pretty_slabels = concatenate_list_data(subset_list(slabels,mask))\n",
    "#texts = []\n",
    "#for n in range(len(subset_list(sigs,mask))): #for n in list_sig\n",
    "#    txt = pretty_slabels[n]\n",
    "#    z,y = subset_list(sigs,mask)[n]\n",
    "#    texts.append(ax.text(z,y,txt,fontsize=12))\n",
    "#adjust_text(texts) \n",
    "#plt.savefig(plot_dir + save_name + \"_effect_significance_1000s.pdf\")\n",
    "\n",
    "fig.savefig(os.path.join(plot_dir, save_name + \"_effect_significance.pdf\"))\n",
    "\n",
    "#df[df.astype(bool)[\"PFC\"] == True][df.astype(bool)[\"NAC\"] == True]\n",
    "\n",
    "def gen_per_cell_plot(df,cell_ids,motif_labels,dcounts,expected,savepath=plot_dir, hide_singlets=True,figsize=(16,35)):\n",
    "    \"\"\"\n",
    "    This plots each cell of a given motif on the same plot as an individual line\n",
    "    Each line's points are the corresponding projection strengths at that region\n",
    "    So this plot shows the projection strengths of all the cells for each motif\n",
    "    \"\"\"\n",
    "    if hide_singlets: #Only show motifs with two or more regions\n",
    "        mask = [i for (i,l) in enumerate(motif_labels) if len(l) > 1]\n",
    "        cell_ids = subset_list(cell_ids,mask)\n",
    "        \n",
    "    non0cell_ids = [(i,x) for (i,x) in enumerate(cell_ids) if len(x) > 0]\n",
    "    dcounts = subset_list(dcounts,mask)\n",
    "    exp_counts_ = subset_list(expected,mask)\n",
    "    obs_ex = []\n",
    "    for i,x in non0cell_ids:\n",
    "        oe = (dcounts[i],exp_counts_[i])\n",
    "        obs_ex.append(oe)\n",
    "    num_plots = len(non0cell_ids)\n",
    "    plot_titles = concatenate_list_data(subset_list(motif_labels,mask))\n",
    "    #print(num_plots)\n",
    "    ncols = 2\n",
    "    nrows = int(np.ceil(num_plots / ncols))\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    n = 1\n",
    "    for cellids_ in non0cell_ids:\n",
    "        \"\"\"if n > 2:\n",
    "            break\"\"\"\n",
    "        i,cellids = cellids_\n",
    "        ax = fig.add_subplot(nrows,ncols,n)\n",
    "        title = plot_titles[i]\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks(np.arange(df.shape[1]))\n",
    "        ax.set_xticklabels(df.columns.to_list())\n",
    "        ax.set_ylabel(\"Projection Strength\")\n",
    "        #x = df[df.index.isin(cellids)].to_numpy()\n",
    "        x = df.iloc[cellids,:].to_numpy()\n",
    "        ## add observed/expected legend\n",
    "        obs,ex = obs_ex[n-1]\n",
    "        textstr = 'Observed: {} \\n Expected: {}'.format(int(obs),int(ex))\n",
    "        # these are matplotlib.patch.Patch properties\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        # place a text box in upper left in axes coords\n",
    "        ax.text(0.55, 0.9, textstr, transform=ax.transAxes, fontsize=14,\n",
    "                verticalalignment='top', bbox=props)\n",
    "        ##\n",
    "        yerr = x.std(axis=0) / np.sqrt(x.shape[0])\n",
    "        #ax.errorbar(x=np.arange(df.shape[1]), y=x.mean(axis=0),yerr=yerr,ecolor='black') # mean with error bars\n",
    "        for j in range(x.shape[0]):\n",
    "            ax.plot(np.arange(df.shape[1]), x[j], markerfacecolor='none', alpha=0.2, c='gray') \n",
    "        ax.errorbar(x=np.arange(df.shape[1]), y=x.mean(axis=0),yerr=yerr,ecolor='gray', c='black',linewidth=3) # mean with error bars\n",
    "        n+=1\n",
    "    if savepath:\n",
    "        fig.savefig(savepath)\n",
    "    return ax\n",
    "\n",
    "#Run the function\n",
    "if full_data:\n",
    "    fig_size2 = (20,140) #(20,140)\n",
    "else:\n",
    "    fig_size2 = (20,10)\n",
    "gprcpplot = gen_per_cell_plot(df,cell_ids,motif_labels,dcounts,exp_counts,figsize=fig_size2, savepath = os.path.join(plot_dir, save_name + \"_per_cell_proj_strength.pdf\"))\n",
    "#\n",
    "#\n",
    "\n",
    "def show_perc_motifs(perc=True):\n",
    "    if perc:\n",
    "        return list(zip(dcounts / (dcounts.sum() / 100),motif_labels))\n",
    "    else:\n",
    "        return list(zip(dcounts,motif_labels))\n",
    "\n",
    "colors = ['white','red']\n",
    "#colors = ['white','blue']\n",
    "'''cm = LinearSegmentedColormap.from_list(\n",
    "        'white_to_red', colors, N=100)'''\n",
    "cm = LinearSegmentedColormap.from_list(\n",
    "        'white_to_red', colors, N=100)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Draw heatmap\n",
    "sn.light_palette(\"#ef6e6e\",n_colors=2,as_cmap=True)\n",
    "order_full = reversed(['LM','AL','RL','A','AM','PM','RSP']) #add 'Cere' to this list if the neg controls are included.\n",
    "order_partial = ['LM','AL','RL','AM','PM']\n",
    "if full_data:\n",
    "    #df_ = df[['PFC','LS','CEA','NAC','BLA','LH','BNST']]\n",
    "    #df_ = df[reversed(['BLA', 'NAC','PFC','LS','BNST','LH','CEA'])]\n",
    "    df_ = df[order_full]\n",
    "else:\n",
    "    df_ = df[order_partial]\n",
    "\n",
    "print(\"Number of Nulls:\")\n",
    "print(df_.isnull().sum())\n",
    "print(\"Number of Nas:\")\n",
    "print(df_.isna().sum())\n",
    "print(\"Number of Infs:\")\n",
    "print(np.isinf(df_).sum())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_ = pd.DataFrame(scaler.fit_transform(df_), columns=df_.columns)\n",
    "\n",
    "clusterfig = sn.clustermap(df_,col_cluster=False,metric='cosine', method='average',\\\n",
    "              cbar_kws=dict(label='Projection Strength'), \\\n",
    "                cmap=cm,vmin=0.0,vmax=1.0)\n",
    "clusterfig.ax_heatmap.set_title(save_name.replace('_',''))\n",
    "clusterfig.ax_heatmap.axes.get_yaxis().set_visible(False)\n",
    "#sn.heatmap(experiment,cbar_kws=dict(shrink=0.5,label='Projection Strength'))\n",
    "#clusterfig.savefig(\"/Users/brandonbrown/Desktop/KheirbekLab/MAPseq/clustermap.pdf\")\n",
    "\n",
    "clusterfig.savefig(os.path.join(plot_dir, save_name + \"_red_white_cluster_heatmap.pdf\"))\n",
    "\n",
    "def gen_prob_matrix(df : pd.DataFrame):\n",
    "    data = df.to_numpy(copy=True)\n",
    "    cells,regions = data.shape\n",
    "    mat = np.zeros((regions,regions)) #area B x area A\n",
    "    #loop over columns (region )\n",
    "    for col in range(regions):\n",
    "        #find all cells (rows in data) that project to 'col'\n",
    "        ids_col = np.where(data[:,col] != 0)[0]\n",
    "        sub_col = data[ids_col]\n",
    "        #of these, how many project to region B\n",
    "        for row in range(regions):\n",
    "            ids_row = np.where(sub_col[:,row] != 0)[0]\n",
    "            if ids_col.shape[0] == 0:\n",
    "                prob = 0\n",
    "            else:\n",
    "                prob = ids_row.shape[0] / ids_col.shape[0]\n",
    "            #print(\"P({} | {}) = {}\".format(df.columns[row],df.columns[col],prob))\n",
    "            mat[col,row] = prob\n",
    "    mat = pd.DataFrame(mat, columns=df.columns)\n",
    "    mat.index = df.columns\n",
    "    return mat\n",
    "\n",
    "probmat = gen_prob_matrix(df)\n",
    "\n",
    "#P(BNST | LS) = 0.5\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.set_title(save_name.replace('_',''),fontsize=20)\n",
    "#colors2 = ['black','red','orange','yellow']\n",
    "colors2 = ['darkblue','#1f9ed1','#26ffc5','#ffc526','yellow']\n",
    "cm2 = LinearSegmentedColormap.from_list(\n",
    "        'white_to_red', colors2, N=100)\n",
    "ax.set_facecolor('#a8a8a8')\n",
    "ax = sn.heatmap(probmat.T,mask=probmat.T == 1,ax=ax,cbar_kws=dict(label='$P(B | A)$'),cmap=cm2) #can add vmax=number for scale\n",
    "ax.set_xlabel(\"Area A\",fontsize=16)\n",
    "ax.set_ylabel(\"Area B\",fontsize=16)\n",
    "plt.savefig(os.path.join(plot_dir, save_name + \"_blueyellow_probability_heatmap.pdf\"))\n",
    "\n",
    "#np.triu(probmat,k=1)[0].mean()\n",
    "\n",
    "def remove_zero_rows(df):\n",
    "    df_ = df.fillna(0)\n",
    "    df = df.loc[~(df_==0).all(axis=1)].astype('float32')\n",
    "    return df\n",
    "\n",
    "def get_overlaps(df):\n",
    "    \"\"\"\n",
    "    Returns the number of cells that target both regions in a pair\n",
    "    \"\"\"\n",
    "    cells,regions = df.shape\n",
    "    pairs = list(itertools.combinations(df.columns,2)) #remove null id\n",
    "    pairs_unzip = list(zip(*pairs))\n",
    "    from_r = list(pairs_unzip[0])\n",
    "    to_r = list(pairs_unzip[1])\n",
    "    counts=[]\n",
    "    df = df.copy()\n",
    "    for i in pairs:\n",
    "        sub = df.T.loc[list(i)].T\n",
    "        sub = remove_zero_rows(sub)\n",
    "        counts.append(sub.shape[0])\n",
    "    res = pd.DataFrame(columns=['from','to','value'])\n",
    "    res['from'] = from_r\n",
    "    res['to'] = to_r\n",
    "    res['value'] = counts\n",
    "    return res #counts, pairs\n",
    "\n",
    "oo = get_overlaps(df)\n",
    "oo.head()\n",
    "\n",
    "def get_motif_count(motif,counts,labels):\n",
    "    \"\"\"\n",
    "    Get the number of cells that project to this specific motif\n",
    "    where motif is a list of column names e.g. ['LH','PFC']\n",
    "    \"\"\"\n",
    "    for i in range(len(labels)):\n",
    "        if set(motif) == set(labels[i]):\n",
    "            return counts[i]\n",
    "\n",
    "get_motif_count(['PM','AL'],dcounts,motif_labels)\n",
    "\n",
    "import re\n",
    "pattern = re.compile('([^\\s\\w]|_)+')\n",
    "\n",
    "def strip_nonchars(string):\n",
    "    strip = pattern.sub('', string)\n",
    "    return strip\n",
    "\n",
    "def findsubsets(S,m):\n",
    "    return set(itertools.combinations(S, m))\n",
    "#findsubsets(df.columns.to_list(),2)\n",
    "\n",
    "#LH, PFC, BLA and NAc\n",
    "def get_pair_reg_props(df,counts,labels):\n",
    "    \"\"\"\n",
    "    Given each pair in region_list, find number of cells that target either in the pair\n",
    "    and then find proportion of cells that target both in pair exclusively\n",
    "    \n",
    "    counts: motif counts\n",
    "    labels: motif labels\n",
    "    \"\"\"\n",
    "    region_list = df.columns.to_list()\n",
    "    R = len(region_list)\n",
    "    tot = df.shape[0] / 100\n",
    "    pairs = findsubsets(region_list,2)\n",
    "    results = []\n",
    "    for i,pair in enumerate(pairs):\n",
    "        p1,p2 = pair\n",
    "        num_cells_p1 = df[df[p1] > 0.].shape[0]\n",
    "        num_cells_p2 = df[df[p2] > 0.].shape[0]\n",
    "        tot_cells = num_cells_p1 + num_cells_p2\n",
    "        num_doublets = get_motif_count([p1,p2],counts,labels)\n",
    "        perc = np.around((100.0 * num_doublets) / tot_cells,3)\n",
    "        results.append((p1,p2,tot_cells,num_doublets,perc))\n",
    "    return results\n",
    "\n",
    "get_pair_reg_props(df,dcounts,motif_labels)\n",
    "\n",
    "def get_all_counts(df,motifs,counts,labels):\n",
    "    \"\"\"\n",
    "    Returns an array where each row is a motif and the counts of \n",
    "    number of cells targeting each member of the motif (non-exclusive), total number of cells targeting any of \n",
    "    the members of the motif, number of cells targeting all members of motif, and percentage exclusively targeting full\n",
    "    motif (relative to any member of the motif), e.g.\n",
    "    columns: PFC BNST LS CeA Total Motif Perc\n",
    "    row 1  : 10   20  30  NA  60    6     10%\n",
    "    where NA means that region is not part of the motif\n",
    "    \n",
    "    Input: df; dataframe of normalized data, Num cells (N) x Num regions (R)\n",
    "    motifs M (num motifs) x R binary matrix indicating which regions present in each motif (row)\n",
    "    counts vector containg counts of cells that exclusively project to each matching motif/row in motifs\n",
    "    labels string labels for regions that make each matching motif in motifs\n",
    "    \"\"\"\n",
    "    ret = pd.DataFrame(columns=df.columns.to_list() + ['Total', 'Motif Num', 'Motif Perc'])\n",
    "    num_cols = len(ret.columns.to_list())\n",
    "    for i,motif in enumerate(motifs): #loop through motifs\n",
    "        m = [index for (index,x) in enumerate(motif) if x]\n",
    "        if len(m) < 1:\n",
    "            continue\n",
    "        sums = df.iloc[:,m].astype(bool).astype(int).sum().to_numpy()\n",
    "        ap = np.zeros(num_cols)\n",
    "        ap[:] = np.nan\n",
    "        ap[m] = sums\n",
    "        ap = ap.reshape(1,ap.shape[0])\n",
    "        ap = pd.DataFrame(ap,columns=ret.columns)\n",
    "        tot = ap.iloc[:,0:-3].dropna(axis=1).to_numpy().sum()\n",
    "        ap.iloc[:,-3] = tot\n",
    "        ap.iloc[:,-2] = counts[i]\n",
    "        # Safeguard against division by zero\n",
    "        if tot == 0:\n",
    "            ap.iloc[:, -1] = 0.0\n",
    "        else:\n",
    "            ap.iloc[:, -1] = 100.0 * (counts[i] / tot)\n",
    "        ret = pd.concat([ret, ap], ignore_index=True)\n",
    "    return ret\n",
    "\n",
    "def get_all_counts_nondf(df,motifs,counts,labels):\n",
    "    \"\"\"\n",
    "    Returns an array where each row is a motif and the columns are the counts of \n",
    "    number of cells targeting each member of the motif (non-exclusive), total number of cells targeting any of \n",
    "    the members of the motif, number of cells targeting all members of motif, and percentage exclusively targeting full\n",
    "    motif (relative to any member of the motif), e.g.\n",
    "    columns: PFC BNST LS CeA Total Motif Perc\n",
    "    row 1  : 10   20  30  NA  60    6     10%\n",
    "    where NA means that region is not part of the motif\n",
    "    \n",
    "    Input: df; dataframe of normalized data, Num cells (N) x Num regions (R)\n",
    "    motifs M (num motifs) x R binary matrix indicating which regions present in each motif (row)\n",
    "    counts vector containg counts of cells that exclusively project to each matching motif/row in motifs\n",
    "    labels string labels for regions that make each matching motif in motifs\n",
    "    \"\"\"\n",
    "    retdf = [] #return list\n",
    "    #each element is a list [Labels, R1 count, R2 count ... Rn count, Total Count, Motif Count, Motif Perc]\n",
    "    for i,motif in enumerate(motifs): #loop through motifs\n",
    "        m = [index for (index,x) in enumerate(motif) if x]\n",
    "        row = list(np.zeros(1+len(m)+3)) #1 (labels) + num-regions-in-motifs + 3 (total,motif count,motif perc)\n",
    "        if len(m) < 1:\n",
    "            continue\n",
    "        sums = df.iloc[:,m].astype(bool).astype(int).sum().to_numpy()\n",
    "        row[0] = labels[i]\n",
    "        row[1:len(m)+1] = sums\n",
    "        tot = sums.sum()\n",
    "        \n",
    "        # Prevent division by zero\n",
    "        if tot == 0:\n",
    "            row[len(m) + 1] = np.nan  # or 0, depending on how you want to handle this case\n",
    "            row[len(m) + 2] = np.nan  # Handle the motif count\n",
    "            row[len(m) + 3] = np.nan  # Handle the motif percentage\n",
    "        else:\n",
    "            row[len(m) + 1] = tot\n",
    "            row[len(m) + 2] = counts[i]\n",
    "            row[len(m) + 3] = 100.0 * (counts[i] / tot)\n",
    "        \n",
    "        #row[len(m)+1] = tot\n",
    "        #row[len(m)+2] = counts[i]\n",
    "        #row[len(m)+3] = 100.0 * (counts[i] / tot)\n",
    "        retdf.append(row)\n",
    "    return retdf\n",
    "\n",
    "unstruct_counts = get_all_counts_nondf(df,motifs,dcounts,motif_labels)\n",
    "#unstruct_counts\n",
    "\n",
    "def write_motif_counts(path,counts):\n",
    "    with open(path, 'w') as f:\n",
    "        for item in counts:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "write_motif_counts(\n",
    "    os.path.join(plot_dir, save_name + '_counts.txt'), \n",
    "    unstruct_counts\n",
    ")\n",
    "\n",
    "mdf = get_all_counts(df,motifs,dcounts,motif_labels)\n",
    "\n",
    "mdf.head()\n",
    "\n",
    "mdf.to_csv(os.path.join(plot_dir, save_name + \"_motif_counts.csv\"))\n",
    "\n",
    "show_perc_motifs(False)\n",
    "\n",
    "def get_target_pie(df : pd.DataFrame):\n",
    "    \"\"\"\n",
    "    For each cell (row), determine how many projections it makes\n",
    "    \"\"\"\n",
    "    data = df.to_numpy(copy=True)\n",
    "    cells,regions = data.shape\n",
    "    res = []#np.zeros(regions)\n",
    "    for cell in range(cells):\n",
    "        num_targets = int(np.nonzero(data[cell])[0].shape[0])\n",
    "        res.append(num_targets)\n",
    "    ret = np.array(res)\n",
    "    #ret = pd.DataFrame(ret)\n",
    "    return ret\n",
    "\n",
    "df_pie = get_target_pie(df)\n",
    "\n",
    "g,c = np.unique(df_pie,return_counts=True)\n",
    "\n",
    "c_row_names = ['1 target']\n",
    "c_row_names += [\"{} targets\".format(i+2) for i in range(c.shape[0]-1)]\n",
    "c = pd.DataFrame(c,columns=['# Cells'], index=c_row_names)\n",
    "c_np = c.to_numpy(copy=True).flatten()\n",
    "c.head()\n",
    "\n",
    "c.to_csv(os.path.join(plot_dir, save_name + \"_pie_chart_data.csv\"))\n",
    "\n",
    "c_tot = c_np.sum()\n",
    "c_tot\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(save_name.replace('_',''))\n",
    "glabels = [\"1 target \\n {:0.3}\\%\".format(100*c_np[0] / c_tot)]\n",
    "glabels += [\"{} targets \\n {:0.3}\\%\".format(i+2,100*j/c_tot) for (i,j) in zip(range(c_np.shape[0]-1),c_np[1:])]\n",
    "patches, texts = plt.pie(c.to_numpy().flatten(),labels=glabels)\n",
    "[txt.set_fontsize(8) for txt in texts]\n",
    "plt.savefig(os.path.join(plot_dir, save_name + \"_num_targets_pie.pdf\"))\n",
    "\n",
    "maxproj = TSNE(n_components=2,metric='cosine').fit_transform(df.to_numpy(copy=True))\n",
    "\n",
    "#maxprojclusters = k_means(X=maxproj,n_clusters=6)\n",
    "\n",
    "tlabels = df.to_numpy(copy=True).argmax(axis=1)\n",
    "#tlabels = km[1]\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.title(save_name.replace('_',''),fontsize=20)\n",
    "plt.xlabel(\"tSNE Component 1\",fontsize=20)\n",
    "plt.ylabel(\"tSNE Component 2\",fontsize=20)\n",
    "sc = plt.scatter(maxproj[:,0],maxproj[:,1],c=tlabels) #c=maxprojclusters[1]\n",
    "cb = plt.colorbar(sc)\n",
    "cb.set_label(\"Maximum Projection Target\",fontsize=20)\n",
    "plt.savefig(os.path.join(plot_dir, save_name + \"_tsne.pdf\"))\n",
    "\n",
    "def prepare_upset_data(df):\n",
    "    #mask1 = [i for (i,x) in enumerate(motif_labels) if len(x) > 1]\n",
    "    mask1 = [i for (i,x) in enumerate(df['Degree'].to_list()) if x > 1]\n",
    "    a = subset_list(df['Motifs'].to_list(), mask1)\n",
    "    b = df['Observed'][mask1]\n",
    "    c = df['Expected'][mask1]\n",
    "    d = df['Expected SD'][mask1]\n",
    "    e = df['Effect Size'][mask1]\n",
    "    f = df['P-value'][mask1]\n",
    "    g = df['Group'][mask1]\n",
    "    mask2 = [i for i in range(b.shape[0]) if b.iloc[i] > 0]\n",
    "    a = subset_list(a, mask2)\n",
    "    b = b.iloc[mask2]\n",
    "    b = b.to_numpy().astype(int)\n",
    "    #\n",
    "    c = c.iloc[mask2]\n",
    "    c = c.to_numpy().astype(int)\n",
    "    #\n",
    "    d = d.iloc[mask2]\n",
    "    #\n",
    "    e = e.iloc[mask2]\n",
    "    #\n",
    "    f = f.iloc[mask2]\n",
    "    #\n",
    "    g = g.iloc[mask2]\n",
    "    dfdata = pd.DataFrame(data=[a,b,c,d,e,f,g]).T\n",
    "    dfdata.columns = ['Motifs', 'Observed', 'Expected', 'Expected SD', 'Effect Size', 'P-value', 'Group']\n",
    "    #dfdata = dfdata.sort_values(by=\"Observed\",ascending=False)\n",
    "    return dfdata\n",
    "\n",
    "sigsraw, slabelsraw = get_motif_sig_pts(dcounts,motif_labels,exclude_zeros=False, p_transform=lambda x:x)\n",
    "\n",
    "effectsigsraw = np.array(sigsraw)\n",
    "expected_sd_raw = np.array([np.sqrt(motif_probs[i] * n0 * (1-motif_probs[i])) for i in range(len(slabelsraw))])\n",
    "\n",
    "degree = [len(x) for x in motif_labels]\n",
    "degree[0] = 0\n",
    "\n",
    "group = []\n",
    "bonferroni_correction = len(slabels)\n",
    "for i in range(len(degree)):\n",
    "    \"\"\"\n",
    "    Group 1: motifs significantly over represented\n",
    "    Group 2: motifs non-sig over-represented\n",
    "    Group 3: motifs non-sig under-represented\n",
    "    Group 4: motifs significantly under represented\n",
    "    \"\"\"\n",
    "    grp = 0\n",
    "    thr = 0.05 / bonferroni_correction\n",
    "    if effectsigsraw[i,0] > 0: #over-represented\n",
    "        if effectsigsraw[i,1] < thr: #statistically significant\n",
    "            grp = 1\n",
    "        else:\n",
    "            grp = 3 #2\n",
    "    else: #under-represented\n",
    "        if effectsigsraw[i,1] > thr:\n",
    "            grp = 4\n",
    "        else: #statistically significant\n",
    "            grp = 2\n",
    "    group.append(grp)\n",
    "\n",
    "dfraw = pd.DataFrame(data=[\n",
    "                           motif_labels,\\\n",
    "                           dcounts,exp_counts.astype(int), \\\n",
    "                          expected_sd_raw,effectsigsraw[:,0], effectsigsraw[:,1], degree, group]).T\n",
    "dfraw.columns=['Motifs','Observed','Expected', 'Expected SD','Effect Size', 'P-value', 'Degree', 'Group']\n",
    "\n",
    "dfraw.to_csv(\n",
    "    os.path.join(plot_dir, save_name + \"_upsetplot.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "dfraw.iloc[40:70]\n",
    "#54\t[LS, BNST, LH]\t14\t11\t3.41421\t1.47675\t0.000194429\t3\t1\n",
    "\n",
    "dfdata = prepare_upset_data(dfraw)\n",
    "dfdata = dfdata.sort_values(by=['Group','Observed'], ascending=[True,False])\n",
    "\n",
    "###CHATGPT OPTIMIZED FOR ANY NUMBER OF GROUPS\n",
    "def kplot(df, size=(30,12)):\n",
    "    \"\"\"\n",
    "    data : pd.DataFrame\n",
    "    data is a dataframe with columns \"Motifs\" and \"Counts\"\n",
    "    where \"Motifs\" is a list of lists e.g. [['PFC','LS'],['LS']]\n",
    "    and \"Counts\" is a simple array of integers\n",
    "    \"\"\"\n",
    "    motiflabels = df['Motifs'].to_list()\n",
    "    data = up.from_memberships(motiflabels, data=df['Observed'].to_numpy())\n",
    "    xlen = df.shape[0]\n",
    "    xticks = np.arange(xlen)\n",
    "    uplot = up.UpSet(data, sort_by=None)  # sort_by='cardinality'\n",
    "    fig, ax = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 3], 'height_ratios': [3, 1]})\n",
    "    fig.set_size_inches(size)\n",
    "    ax[1, 0].set_ylabel(\"Set Totals\")\n",
    "    uplot.plot_matrix(ax[1, 1])\n",
    "    uplot.plot_totals(ax[1, 0])\n",
    "    ax[0, 0].axis('off')\n",
    "    ax[0, 1].spines['bottom'].set_visible(False)\n",
    "    ax[0, 1].spines['top'].set_visible(False)\n",
    "    ax[0, 1].spines['right'].set_visible(False)\n",
    "    \n",
    "    width = 0.35\n",
    "    dodge = width / 2\n",
    "    x = np.arange(8)\n",
    "    ax[1, 0].set_title(\"Totals\")\n",
    "    ax[0, 1].set_ylabel(\"Counts\")\n",
    "    ax[0, 1].set_xlim(ax[1, 1].get_xlim())\n",
    "    \n",
    "    # Get unique group labels and create color map for each group dynamically\n",
    "    unique_groups = df['Group'].unique()\n",
    "    colorlist = ['red', 'darkblue', 'black', 'green', 'purple']  # Extend as needed\n",
    "    color_map = {group: colorlist[i % len(colorlist)] for i, group in enumerate(unique_groups)}\n",
    "    \n",
    "    # Map the colors based on the group\n",
    "    cs = [color_map[group] for group in df['Group']]\n",
    "    \n",
    "    # Plot the bars with colors\n",
    "    ax[0, 1].bar(xticks - dodge, df['Observed'].to_numpy(), width=width, label=\"Observed\", align=\"center\", color=cs, edgecolor='lightgray')\n",
    "    ax[0, 1].bar(xticks + dodge, df['Expected'].to_numpy(), yerr=df['Expected SD'].to_numpy(), width=width / 2, label=\"Expected\", align=\"center\", color='gray', alpha=0.5, ecolor='lightgray')\n",
    "    \n",
    "    # Draw significance asterisks\n",
    "    for group in unique_groups:\n",
    "        group_ids = np.where(df['Group'].to_numpy() == group)[0]\n",
    "        for i in group_ids:\n",
    "            ax[0, 1].text(xticks[i] - 0.5 * dodge, df['Observed'].to_numpy()[i] + 1, \"*\", fontsize=12, color=color_map[group])\n",
    "\n",
    "    # Hide axis ticks and grids\n",
    "    ax[0, 1].xaxis.grid(False)\n",
    "    ax[0, 1].xaxis.set_visible(False)\n",
    "    ax[1, 1].xaxis.set_visible(False)\n",
    "    ax[1, 1].xaxis.grid(False)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "fig, _ = kplot(dfdata)\n",
    "fig.savefig(os.path.join(plot_dir, save_name + \"_upsetplot_gpt.pdf\"))\n",
    "\n",
    "def kplot(df, size=(30,12)):\n",
    "    \"\"\"\n",
    "    data : pd.DataFrame\n",
    "    data is a dataframe with columns \"Motifs\" and \"Counts\"\n",
    "    where \"Motifs\" is a list of lists e.g. [['PFC','LS'],['LS']]\n",
    "    and \"Counts\" is a simple array of integers\n",
    "    \"\"\"\n",
    "    motiflabels = df['Motifs'].to_list()\n",
    "    data = up.from_memberships(motiflabels,data=df['Observed'].to_numpy())\n",
    "    xlen = df.shape[0]\n",
    "    xticks = np.arange(xlen)\n",
    "    uplot = up.UpSet(data, sort_by=None) #sort_by='cardinality'\n",
    "    fig,ax=plt.subplots(2,2,gridspec_kw={'width_ratios': [1, 3], 'height_ratios':[3,1]})\n",
    "    fig.set_size_inches(size)\n",
    "    ax[1,0].set_ylabel(\"Set Totals\")\n",
    "    uplot.plot_matrix(ax[1,1])\n",
    "    uplot.plot_totals(ax[1,0])\n",
    "    ax[0,0].axis('off')\n",
    "    ax[0,1].spines['bottom'].set_visible(False)\n",
    "    ax[0,1].spines['top'].set_visible(False)\n",
    "    ax[0,1].spines['right'].set_visible(False)\n",
    "    #ax[0,1].set_xticks([],[])\n",
    "    width=0.35\n",
    "    dodge=width/2\n",
    "    x = np.arange(8)\n",
    "    ax[1,0].set_title(\"Totals\")\n",
    "    ax[0,1].set_ylabel(\"Counts\")\n",
    "    #ax[0,1].set_xlim(-width,8)\n",
    "    ax[0,1].set_xlim(ax[1,1].get_xlim())\n",
    "    #ax[0,1].set_xticks(ax[1,1].get_xticks())\n",
    "    ox = xticks-dodge\n",
    "    ex = xticks+dodge\n",
    "    #colorlist = ['cyan','darkgray','darkgray','red']\n",
    "    colorlist = ['red','darkblue','black','black']\n",
    "    cs = [colorlist[i-1] for i in df['Group']]\n",
    "    ax[0,1].bar(ox,df['Observed'].to_numpy(),width=width,label=\"Observed\", align=\"center\",color=cs, edgecolor='lightgray')\n",
    "    ax[0,1].bar(ex,df['Expected'].to_numpy(),yerr=df['Expected SD'].to_numpy(),width=width/2,label=\"Expected\", align=\"center\",color='gray',alpha=0.5,ecolor='lightgray')\n",
    "    #draw group lines\n",
    "    #g2 = np.where(dfdata['Group'].to_numpy() == 2)[0][0]\n",
    "    #g4 = np.where(dfdata['Group'].to_numpy() == 4)[0][0]\n",
    "    #ax[0,1].axvline(ex[g2]-1+1.5*dodge,color='black')\n",
    "    #ax[0,1].axvline(ex[g4]-1+1.5*dodge,color='black')\n",
    "    #add asterisks for significance\n",
    "    grp_ = dfdata['Group'].to_numpy()\n",
    "    idsig = np.concatenate([np.where(grp_ == 1)[0],np.where(grp_ == 2)[0]])\n",
    "    [ax[0,1].text(ox[idsig][i]-0.5*dodge,df['Observed'].to_numpy()[idsig][i]+1,s=\"*\") for i in range(idsig.shape[0])]\n",
    "    # \n",
    "    ax[0,1].xaxis.grid(False)\n",
    "    ax[0,1].xaxis.set_visible(False)\n",
    "    ax[1,1].xaxis.set_visible(False)\n",
    "    ax[1,1].xaxis.grid(False)\n",
    "    #ax[0,1].legend()\n",
    "    fig.tight_layout()\n",
    "    return fig,ax\n",
    "\n",
    "fig,_ = kplot(dfdata)\n",
    "\n",
    "fig.savefig(os.path.join(plot_dir, save_name + \"_upsetplot.pdf\"))\n",
    "\n",
    "#LH-BNST-LS  is put as significant but overlaps with SD of expected\n",
    "#LS+BNST+LH\t1.476751\t0.000194\n",
    "\n",
    "df.astype(bool).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55582b35-668a-44d0-a0ec-c0557a19e0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
